import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris
from ucimlrepo import fetch_ucirepo
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.decomposition import PCA

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="k-NN Interactive Analyzer",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado para melhorar a apar√™ncia
st.markdown("""
<style>
.main-header {
    font-size: 2.5rem;
    color: #1f77b4;
    text-align: center;
    margin-bottom: 2rem;
}
.dataset-info {
    background-color: #f0f2f6;
    padding: 1rem;
    border-radius: 0.5rem;
    margin: 1rem 0;
}
.metric-card {
    background-color: #ffffff;
    padding: 1rem;
    border-radius: 0.5rem;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_dataset(dataset_choice):
    """Carrega o dataset escolhido"""
    if dataset_choice == "Iris":
        iris = load_iris()
        X = pd.DataFrame(iris.data, columns=iris.feature_names)
        y = pd.Series(iris.target)
        target_names = iris.target_names.tolist()
        # Ensure y values are valid indices
        y = y.astype(int)
        return X, y, target_names, "Classifica√ß√£o de esp√©cies de flores Iris"
    
    elif dataset_choice == "Wine":
        try:
            wine = fetch_ucirepo(id=109)
            X = pd.DataFrame(wine.data.features)
            y = pd.Series(wine.data.targets.values.ravel())
            
            # Fix the target encoding - ensure consecutive integers starting from 0
            le = LabelEncoder()
            y = pd.Series(le.fit_transform(y))
            target_names = [f"Classe {int(c)}" for c in sorted(le.classes_)]
            
            return X, y, target_names, "Classifica√ß√£o de qualidade de vinhos"
        except Exception as e:
            st.error(f"Erro ao carregar dataset Wine: {str(e)}. Usando Iris como padr√£o.")
            return load_dataset("Iris")

def safe_target_mapping(y, target_names):
    """Safely map target indices to names"""
    try:
        # Ensure all y values are valid indices
        y_mapped = []
        for val in y:
            if isinstance(val, (int, np.integer)) and 0 <= val < len(target_names):
                y_mapped.append(target_names[val])
            else:
                # Handle invalid indices
                y_mapped.append(f"Unknown_{val}")
        return y_mapped
    except Exception as e:
        st.error(f"Error mapping targets: {str(e)}")
        return [f"Class_{i}" for i in y]

def create_data_overview(X, y, target_names, description):
    """Cria visualiza√ß√£o geral dos dados"""
    st.markdown(f"<h3>üìä {description}</h3>", unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìà Amostras", len(X))
    with col2:
        st.metric("üîß Features", len(X.columns))
    with col3:
        st.metric("üéØ Classes", len(target_names))
    with col4:
        balance_text = "Balanceado" if y.value_counts().std() < 5 else "Desbalanceado"
        st.metric("üìä Balan√ßo", balance_text)
    
    # Distribui√ß√£o das classes - use safe mapping
    y_labels = safe_target_mapping(y, target_names)
    
    fig_dist = px.histogram(
        x=y_labels, 
        title="üéØ Distribui√ß√£o das Classes",
        labels={'x': 'Classes', 'y': 'N√∫mero de Amostras'},
        color=y_labels
    )
    fig_dist.update_layout(showlegend=False, height=400)
    st.plotly_chart(fig_dist, use_container_width=True)

def create_feature_analysis(X, y, target_names):
    """An√°lise detalhada das features"""
    st.markdown("### üîç An√°lise das Features")
    
    # Estat√≠sticas descritivas
    with st.expander("üìã Estat√≠sticas Descritivas"):
        st.dataframe(X.describe().round(3))
    
    # Correla√ß√£o entre features
    col1, col2 = st.columns(2)
    
    with col1:
        fig_corr = px.imshow(
            X.corr().round(2),
            text_auto=True,
            title="üîó Matriz de Correla√ß√£o",
            color_continuous_scale="RdBu"
        )
        st.plotly_chart(fig_corr, use_container_width=True)
    
    with col2:
        # Boxplot das features por classe
        feature_selected = st.selectbox("Selecione uma feature para an√°lise:", X.columns)
        
        # Safe mapping for boxplot
        y_labels = safe_target_mapping(y, target_names)
        
        df_plot = pd.DataFrame({
            'Feature': X[feature_selected],
            'Classe': y_labels
        })
        
        fig_box = px.box(
            df_plot, 
            x='Classe', 
            y='Feature',
            title=f"üìä Distribui√ß√£o de {feature_selected} por Classe",
            color='Classe'
        )
        st.plotly_chart(fig_box, use_container_width=True)

def create_pca_visualization(X, y, target_names):
    """Visualiza√ß√£o PCA dos dados"""
    st.markdown("### üé® Visualiza√ß√£o PCA")
    
    # Aplica PCA
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(StandardScaler().fit_transform(X))
    
    # Safe mapping for PCA plot
    y_labels = safe_target_mapping(y, target_names)
    
    # Cria DataFrame para plotagem
    df_pca = pd.DataFrame({
        'PC1': X_pca[:, 0],
        'PC2': X_pca[:, 1],
        'Classe': y_labels
    })
    
    fig_pca = px.scatter(
        df_pca, 
        x='PC1', 
        y='PC2', 
        color='Classe',
        title=f"üé® Visualiza√ß√£o PCA - Vari√¢ncia Explicada: {pca.explained_variance_ratio_.sum():.3f}",
        labels={'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.3f})',
                'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.3f})'}
    )
    fig_pca.update_traces(marker=dict(size=10))
    st.plotly_chart(fig_pca, use_container_width=True)
    
    return pca, X_pca

def run_knn_analysis(X, y, target_names, k_value, test_size, random_state):
    """Executa an√°lise k-NN"""
    
    # Ensure y is properly encoded
    if not all(isinstance(val, (int, np.integer)) and 0 <= val < len(target_names) for val in y):
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
    else:
        y_encoded = y.copy()
    
    # Divis√£o dos dados
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=test_size, random_state=random_state, stratify=y_encoded
    )
    
    # Padroniza√ß√£o
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Treinamento
    knn = KNeighborsClassifier(n_neighbors=k_value)
    knn.fit(X_train_scaled, y_train)
    
    # Predi√ß√µes
    y_pred = knn.predict(X_test_scaled)
    
    # M√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    
    # --- IN√çCIO DA MODIFICA√á√ÉO ---
    # Calcular o relat√≥rio de classifica√ß√£o completo
    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)

    # Extrair as m√©tricas macro (que consideram a m√©dia entre as classes)
    precision_macro = report['macro avg']['precision']
    recall_macro = report['macro avg']['recall']
    f1_macro = report['macro avg']['f1-score']
    # --- FIM DA MODIFICA√á√ÉO ---

    # Create target names list that matches the encoded labels
    available_labels = sorted(list(set(y_test) | set(y_pred)))
    target_names_subset = [target_names[i] if i < len(target_names) else f"Class_{i}" for i in available_labels]
    
    report_dict = classification_report(y_test, y_pred, target_names=target_names_subset, output_dict=True, zero_division=0)
    cm = confusion_matrix(y_test, y_pred)
    
    return {
        'accuracy': accuracy,
        'y_test': y_test,
        'y_pred': y_pred,
        'report_dict': report_dict,
        'confusion_matrix': cm,
        'model': knn,
        'scaler': scaler,
        'available_labels': available_labels
    }

def create_results_visualization(results, target_names, k_value):
    """Visualiza resultados do modelo"""
    st.markdown("### üìà Resultados do Modelo")
    
    # M√©tricas principais
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üéØ Acur√°cia", f"{results['accuracy']:.3f}")
    with col2:
        correct = sum(results['y_test'] == results['y_pred'])
        st.metric("‚úÖ Acertos", f"{correct}/{len(results['y_test'])}")
    with col3:
        errors = len(results['y_test']) - correct
        st.metric("‚ùå Erros", str(errors))
    
    # Matriz de confus√£o interativa
    col1, col2 = st.columns(2)
    
    with col1:
        # Get the target names for available labels
        available_labels = results['available_labels']
        target_names_subset = [target_names[i] if i < len(target_names) else f"Class_{i}" for i in available_labels]
        
        fig_cm = px.imshow(
            results['confusion_matrix'],
            text_auto=True,
            labels={'x': 'Predito', 'y': 'Real'},
            title="üîÑ Matriz de Confus√£o",
            color_continuous_scale="Blues"
        )
        
        if len(target_names_subset) <= len(available_labels):
            fig_cm.update_xaxes(ticktext=target_names_subset, tickvals=list(range(len(target_names_subset))))
            fig_cm.update_yaxes(ticktext=target_names_subset, tickvals=list(range(len(target_names_subset))))
        
        st.plotly_chart(fig_cm, use_container_width=True)
    
    with col2:
        # M√©tricas por classe
        try:
            report_df = pd.DataFrame(results['report_dict']).transpose().round(3)
            report_df = report_df.drop(['accuracy', 'macro avg', 'weighted avg'], errors='ignore')
            
            # Gr√°fico de barras das m√©tricas
            metrics_data = []
            for metric in ['precision', 'recall', 'f1-score']:
                for idx, class_name in enumerate(target_names_subset):
                    if class_name in report_df.index and metric in report_df.columns:
                        metrics_data.append({
                            'Classe': class_name,
                            'M√©trica': metric.title(),
                            'Valor': report_df.loc[class_name, metric]
                        })
            
            if metrics_data:
                fig_metrics = px.bar(
                    pd.DataFrame(metrics_data),
                    x='Classe',
                    y='Valor',
                    color='M√©trica',
                    title="üìä M√©tricas por Classe",
                    barmode='group'
                )
                fig_metrics.update_yaxes(range=[0, 1])
                st.plotly_chart(fig_metrics, use_container_width=True)
        except Exception as e:
            st.error(f"Erro ao criar visualiza√ß√£o de m√©tricas: {str(e)}")

def k_optimization_analysis(X, y, target_names, test_size, random_state):
    """An√°lise de otimiza√ß√£o do k"""
    st.markdown("### üîß Otimiza√ß√£o do Hiperpar√¢metro k")
    
    # Explica√ß√£o do crit√©rio de desempate
    with st.expander("‚ÑπÔ∏è Crit√©rio de Desempate"):
        st.markdown("""
        **Crit√©rio para escolha do melhor k:**
        1. **M√°xima Acur√°cia**: Primeiro, seleciona os valores de k com maior acur√°cia
        2. **Menor Complexidade**: Em caso de empate, escolhe o **menor k** porque:
           - ‚úÖ Menor complexidade computacional
           - ‚úÖ Menor chance de overfitting
           - ‚úÖ Decis√µes baseadas em vizinhos mais pr√≥ximos
           - ‚úÖ Modelo mais simples e interpret√°vel
        
        **Por que k menor √© melhor em empates?**
        - k=1: Usa apenas o vizinho mais pr√≥ximo (mais local)
        - k=5: Usa 5 vizinhos (mais global, pode incluir ru√≠do)
        - Princ√≠pio da Navalha de Occam: "A explica√ß√£o mais simples √© geralmente a melhor"
        """)
    
    max_k = min(20, len(X) // 5)
    k_range = range(1, max_k + 1)
    
    with st.spinner("Testando diferentes valores de k..."):
        k_results = []
        
        for k in k_range:
            try:
                results = run_knn_analysis(X, y, target_names, k, test_size, random_state)
                k_results.append({
                    'k': k,
                    'accuracy': results['accuracy'],
                    'errors': len(results['y_test']) - sum(results['y_test'] == results['y_pred'])
                })
            except Exception as e:
                st.warning(f"Erro para k={k}: {str(e)}")
                continue
    
    if not k_results:
        st.error("N√£o foi poss√≠vel executar a otimiza√ß√£o de k")
        return 5
    
    k_df = pd.DataFrame(k_results)
    
    # Gr√°fico da evolu√ß√£o da acur√°cia
    fig_k = go.Figure()
    
    fig_k.add_trace(go.Scatter(
        x=k_df['k'],
        y=k_df['accuracy'],
        mode='lines+markers',
        name='Acur√°cia',
        line=dict(color='#1f77b4', width=3),
        marker=dict(size=8)
    ))
    
    # Encontra o melhor k (menor k em caso de empate na acur√°cia)
    max_accuracy = k_df['accuracy'].max()
    best_candidates = k_df[k_df['accuracy'] == max_accuracy]
    best_k_idx = best_candidates['k'].idxmin()  # Menor k entre os que t√™m max accuracy
    best_k = k_df.loc[best_k_idx]
    
    fig_k.add_trace(go.Scatter(
        x=[best_k['k']],
        y=[best_k['accuracy']],
        mode='markers',
        name=f'Melhor k = {int(best_k["k"])}',
        marker=dict(color='red', size=15, symbol='star')
    ))
    
    fig_k.update_layout(
        title="üìà Evolu√ß√£o da Acur√°cia por Valor de k",
        xaxis_title="Valor de k",
        yaxis_title="Acur√°cia",
        hovermode='x unified'
    )
    
    st.plotly_chart(fig_k, use_container_width=True)
    
    # Tabela com resultados
    k_df_display = k_df.copy()
    k_df_display['accuracy'] = k_df_display['accuracy'].round(4)
    st.dataframe(k_df_display.set_index('k'), use_container_width=True)
    
    success_msg = f"üèÜ Melhor k encontrado: **{int(best_k['k'])}** (Acur√°cia: {best_k['accuracy']:.4f})"
    if len(best_candidates) > 1:
        success_msg += f" - Escolhido menor k entre {len(best_candidates)} empates"
    st.success(success_msg)
    
    return int(best_k['k'])

# Substitua sua fun√ß√£o inteira por esta
# Vers√£o FINAL da fun√ß√£o. Substitua a sua por esta.
def run_exercise_analysis(X, y, target_names, k_values, sample_sizes, initial_random_state):
    """Executa an√°lise sistem√°tica, mostra os resultados e oferece exporta√ß√£o em CSV."""
    st.markdown("### üìã An√°lise Sistem√°tica - Exerc√≠cio")
    
    n_repetitions = 10
    st.info(f"Executando cada configura√ß√£o {n_repetitions} vezes para calcular m√©dia e desvio padr√£o.")

    all_results = [] 
    
    with st.spinner(f"Executando {len(sample_sizes) * len(k_values) * n_repetitions} experimentos..."):
        # ... (o loop de execu√ß√£o continua exatamente o mesmo de antes, sem altera√ß√µes) ...
        progress_bar = st.progress(0)
        total_experiments = len(k_values) * len(sample_sizes) * n_repetitions
        current_experiment = 0
        for i in range(n_repetitions):
            current_random_state = initial_random_state + i
            for sample_size in sample_sizes:
                try:
                    X_subset, y_subset = create_balanced_subset(X, y, sample_size, current_random_state)
                    for k in k_values:
                        current_experiment += 1
                        progress_bar.progress(current_experiment / total_experiments)
                        try:
                            X_train, X_test, y_train, y_test = train_test_split(
                                X_subset, y_subset, test_size=0.2, random_state=current_random_state, stratify=y_subset
                            )
                            scaler = StandardScaler()
                            X_train_scaled = scaler.fit_transform(X_train)
                            X_test_scaled = scaler.transform(X_test)
                            knn = KNeighborsClassifier(n_neighbors=k)
                            knn.fit(X_train_scaled, y_train)
                            y_pred = knn.predict(X_test_scaled)
                            
                            accuracy = accuracy_score(y_test, y_pred)
                            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0, labels=np.unique(y_subset))
                            precision_macro = report['macro avg']['precision']
                            recall_macro = report['macro avg']['recall']
                            f1_macro = report['macro avg']['f1-score']

                            all_results.append({
                                'Tamanho_Amostra': sample_size, 'K': k, 'Acuracia': accuracy,
                                'Precisao': precision_macro, 'Revocacao': recall_macro, 'F1-Score': f1_macro
                            })
                        except Exception:
                            pass
                except Exception as e:
                    st.error(f"Erro ao criar subset com {sample_size} amostras na repeti√ß√£o {i+1}: {str(e)}")

    if all_results:
        results_df = pd.DataFrame(all_results)
        grouped = results_df.groupby(['Tamanho_Amostra', 'K'])
        mean_results = grouped.mean()
        std_results = grouped.std().fillna(0)

        def format_mean_std(mean_df, std_df, metric):
            formatted_series = (mean_df[metric].round(3).astype(str) + " ¬± " + std_df[metric].round(3).astype(str))
            return formatted_series.unstack()

        metrics_to_show = {'Acuracia': 'Acur√°cia', 'F1-Score': 'F1-Score Macro', 'Precisao': 'Precis√£o Macro', 'Revocacao': 'Revoca√ß√£o Macro'}
        for key, title in metrics_to_show.items():
            st.markdown(f"#### üìä Tabela de Resultados ({title}: M√©dia ¬± Desvio Padr√£o)")
            pivot_table = format_mean_std(mean_results, std_results, key)
            st.dataframe(pivot_table, use_container_width=True)

        # <<< IN√çCIO DA MUDAN√áA: ADICIONAR BOT√ÉO DE DOWNLOAD PARA AS TABELAS >>>
        st.markdown("---")
        # Prepara um √∫nico DataFrame com todos os resultados num√©ricos para exporta√ß√£o
        export_df = mean_results.join(std_results, lsuffix='_mean', rsuffix='_std')
        
        st.download_button(
           label="üì• Baixar Todas as Tabelas de M√©tricas (CSV)",
           data=export_df.to_csv().encode('utf-8'),
           file_name='resultados_metricas.csv',
           mime='text/csv',
        )
        # <<< FIM DA MUDAN√áA >>>

        pivot_accuracy_mean = mean_results['Acuracia'].unstack()
        fig_heatmap = px.imshow(pivot_accuracy_mean.values, x=[f"K={k}" for k in pivot_accuracy_mean.columns],
                                y=[f"Amostras={s}" for s in pivot_accuracy_mean.index],
                                color_continuous_scale="Viridis", title="üî• Mapa de Calor: Acur√°cia M√©dia", text_auto=".3f")
        st.plotly_chart(fig_heatmap, use_container_width=True)
        
        st.markdown("#### üìà An√°lise de Tend√™ncias (baseada na m√©dia de 10 execu√ß√µes)")
        col1, col2 = st.columns(2)
        with col1:
            fig_k_trend = px.line(mean_results.reset_index().groupby('K')['Acuracia'].mean().reset_index(),
                                  x='K', y='Acuracia', title="Tend√™ncia da Acur√°cia M√©dia por K", markers=True)
            st.plotly_chart(fig_k_trend, use_container_width=True)
        with col2:
            fig_sample_trend = px.line(mean_results.reset_index().groupby('Tamanho_Amostra')['Acuracia'].mean().reset_index(),
                                       x='Tamanho_Amostra', y='Acuracia', title="Tend√™ncia da Acur√°cia M√©dia por Tamanho da Amostra", markers=True)
            st.plotly_chart(fig_sample_trend, use_container_width=True)

        st.markdown("---")
        st.markdown("#### üîÑ Matriz de Confus√£o M√©dia (para a melhor configura√ß√£o)")

        best_config = mean_results['Acuracia'].idxmax()
        best_sample_size, best_k = best_config
        st.success(f"Melhor configura√ß√£o encontrada: **{best_sample_size} amostras/classe** com **K={best_k}** (Acur√°cia M√©dia: {mean_results.loc[best_config]['Acuracia']:.3f})")

        confusion_matrices = []
        for i in range(n_repetitions):
            current_random_state = initial_random_state + i
            try:
                X_subset, y_subset = create_balanced_subset(X, y, best_sample_size, current_random_state)
                X_train, X_test, y_train, y_test = train_test_split(
                    X_subset, y_subset, test_size=0.2, random_state=current_random_state, stratify=y_subset
                )
                scaler = StandardScaler().fit(X_train)
                X_train_scaled, X_test_scaled = scaler.transform(X_train), scaler.transform(X_test)
                
                knn = KNeighborsClassifier(n_neighbors=best_k)
                knn.fit(X_train_scaled, y_train)
                y_pred = knn.predict(X_test_scaled)
                
                labels = sorted(y_subset.unique())
                cm = confusion_matrix(y_test, y_pred, labels=labels)
                confusion_matrices.append(cm)
            except Exception:
                continue

        if confusion_matrices:
            mean_cm = np.mean(confusion_matrices, axis=0)
            fig_cm = px.imshow(mean_cm, text_auto='.2f', labels={'x': 'Predito', 'y': 'Real'},
                               x=target_names, y=target_names, title=f"Matriz de Confus√£o M√©dia (K={best_k}, Amostras={best_sample_size})",
                               color_continuous_scale="Blues")
            st.plotly_chart(fig_cm, use_container_width=True)

            # <<< IN√çCIO DA MUDAN√áA: ADICIONAR BOT√ÉO DE DOWNLOAD PARA A MATRIZ DE CONFUS√ÉO >>>
            mean_cm_df = pd.DataFrame(mean_cm, index=target_names, columns=target_names)
            st.download_button(
               label="üì• Baixar Matriz de Confus√£o M√©dia (CSV)",
               data=mean_cm_df.to_csv().encode('utf-8'),
               file_name='matriz_confusao_media.csv',
               mime='text/csv',
            )
            # <<< FIM DA MUDAN√áA >>>
    else:
        st.error("Nenhum resultado foi gerado. Verifique as configura√ß√µes e os dados de entrada.")
    return None
    """Executa an√°lise sistem√°tica do exerc√≠cio variando K, tamanho das amostras e repetindo N vezes."""
    st.markdown("### üìã An√°lise Sistem√°tica - Exerc√≠cio")
    
    n_repetitions = 10
    st.info(f"Executando cada configura√ß√£o {n_repetitions} vezes para calcular m√©dia e desvio padr√£o.")

    all_results = [] 
    
    with st.spinner(f"Executando {len(sample_sizes) * len(k_values) * n_repetitions} experimentos..."):
        progress_bar = st.progress(0)
        total_experiments = len(k_values) * len(sample_sizes) * n_repetitions
        current_experiment = 0

        for i in range(n_repetitions):
            current_random_state = initial_random_state + i
            for sample_size in sample_sizes:
                try:
                    X_subset, y_subset = create_balanced_subset(X, y, sample_size, current_random_state)
                    for k in k_values:
                        current_experiment += 1
                        progress_bar.progress(current_experiment / total_experiments)
                        try:
                            X_train, X_test, y_train, y_test = train_test_split(
                                X_subset, y_subset, test_size=0.2, random_state=current_random_state, stratify=y_subset
                            )
                            scaler = StandardScaler()
                            X_train_scaled = scaler.fit_transform(X_train)
                            X_test_scaled = scaler.transform(X_test)
                            knn = KNeighborsClassifier(n_neighbors=k)
                            knn.fit(X_train_scaled, y_train)
                            y_pred = knn.predict(X_test_scaled)
                            
                            accuracy = accuracy_score(y_test, y_pred)
                            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0, labels=np.unique(y_subset))
                            precision_macro = report['macro avg']['precision']
                            recall_macro = report['macro avg']['recall']
                            f1_macro = report['macro avg']['f1-score']

                            all_results.append({
                                'Tamanho_Amostra': sample_size, 'K': k, 'Acuracia': accuracy,
                                'Precisao': precision_macro, 'Revocacao': recall_macro, 'F1-Score': f1_macro
                            })
                        except Exception:
                            pass
                except Exception as e:
                    st.error(f"Erro ao criar subset com {sample_size} amostras na repeti√ß√£o {i+1}: {str(e)}")

    if all_results:
        results_df = pd.DataFrame(all_results)
        grouped = results_df.groupby(['Tamanho_Amostra', 'K'])
        mean_results = grouped.mean()
        std_results = grouped.std().fillna(0)

        def format_mean_std(mean_df, std_df, metric):
            formatted_series = (mean_df[metric].round(3).astype(str) + " ¬± " + std_df[metric].round(3).astype(str))
            return formatted_series.unstack()

        metrics_to_show = {'Acuracia': 'Acur√°cia', 'F1-Score': 'F1-Score Macro', 'Precisao': 'Precis√£o Macro', 'Revocacao': 'Revoca√ß√£o Macro'}
        for key, title in metrics_to_show.items():
            st.markdown(f"#### üìä Tabela de Resultados ({title}: M√©dia ¬± Desvio Padr√£o)")
            pivot_table = format_mean_std(mean_results, std_results, key)
            st.dataframe(pivot_table, use_container_width=True)
        
        pivot_accuracy_mean = mean_results['Acuracia'].unstack()
        fig_heatmap = px.imshow(pivot_accuracy_mean.values, x=[f"K={k}" for k in pivot_accuracy_mean.columns],
                                y=[f"Amostras={s}" for s in pivot_accuracy_mean.index],
                                color_continuous_scale="Viridis", title="üî• Mapa de Calor: Acur√°cia M√©dia", text_auto=".3f")
        st.plotly_chart(fig_heatmap, use_container_width=True)
        
        st.markdown("#### üìà An√°lise de Tend√™ncias (baseada na m√©dia de 10 execu√ß√µes)")
        col1, col2 = st.columns(2)
        with col1:
            fig_k_trend = px.line(mean_results.reset_index().groupby('K')['Acuracia'].mean().reset_index(),
                                  x='K', y='Acuracia', title="Tend√™ncia da Acur√°cia M√©dia por K", markers=True)
            st.plotly_chart(fig_k_trend, use_container_width=True)
        with col2:
            fig_sample_trend = px.line(mean_results.reset_index().groupby('Tamanho_Amostra')['Acuracia'].mean().reset_index(),
                                       x='Tamanho_Amostra', y='Acuracia', title="Tend√™ncia da Acur√°cia M√©dia por Tamanho da Amostra", markers=True)
            st.plotly_chart(fig_sample_trend, use_container_width=True)

        # <<< IN√çCIO DA MUDAN√áA: ADICIONAR MATRIZ DE CONFUS√ÉO M√âDIA >>>
        st.markdown("---")
        st.markdown("#### üîÑ Matriz de Confus√£o M√©dia (para a melhor configura√ß√£o)")

        # 1. Encontrar a melhor configura√ß√£o (maior acur√°cia m√©dia)
        best_config = mean_results['Acuracia'].idxmax()
        best_sample_size, best_k = best_config
        st.success(f"Melhor configura√ß√£o encontrada: **{best_sample_size} amostras/classe** com **K={best_k}** (Acur√°cia M√©dia: {mean_results.loc[best_config]['Acuracia']:.3f})")

        # 2. Roda os testes novamente apenas para a melhor config, salvando as matrizes
        confusion_matrices = []
        for i in range(n_repetitions):
            current_random_state = initial_random_state + i
            try:
                X_subset, y_subset = create_balanced_subset(X, y, best_sample_size, current_random_state)
                X_train, X_test, y_train, y_test = train_test_split(
                    X_subset, y_subset, test_size=0.2, random_state=current_random_state, stratify=y_subset
                )
                scaler = StandardScaler().fit(X_train)
                X_train_scaled, X_test_scaled = scaler.transform(X_train), scaler.transform(X_test)
                
                knn = KNeighborsClassifier(n_neighbors=best_k)
                knn.fit(X_train_scaled, y_train)
                y_pred = knn.predict(X_test_scaled)
                
                # Garante que a matriz tenha o tamanho correto (n√∫mero de classes)
                labels = sorted(y_subset.unique())
                cm = confusion_matrix(y_test, y_pred, labels=labels)
                confusion_matrices.append(cm)
            except Exception:
                continue # Pula se houver erro em uma das execu√ß√µes

        # 3. Calcula a m√©dia e exibe
        if confusion_matrices:
            mean_cm = np.mean(confusion_matrices, axis=0)
            fig_cm = px.imshow(
                mean_cm,
                text_auto='.2f', # Formata para 2 casas decimais
                labels={'x': 'Predito', 'y': 'Real'},
                x=target_names,
                y=target_names,
                title=f"Matriz de Confus√£o M√©dia (K={best_k}, Amostras={best_sample_size})",
                color_continuous_scale="Blues"
            )
            st.plotly_chart(fig_cm, use_container_width=True)
        # <<< FIM DA MUDAN√áA >>>

    else:
        st.error("Nenhum resultado foi gerado. Verifique as configura√ß√µes e os dados de entrada.")
    return None
    """Executa an√°lise sistem√°tica do exerc√≠cio variando K, tamanho das amostras e repetindo N vezes."""
    st.markdown("### üìã An√°lise Sistem√°tica - Exerc√≠cio")
    
    # <<< MUDAN√áA 1: Definir o n√∫mero de repeti√ß√µes >>>
    n_repetitions = 10
    st.info(f"Executando cada configura√ß√£o {n_repetitions} vezes para calcular m√©dia e desvio padr√£o.")

    all_results = [] # Trocamos o nome para refletir que guardar√° todos os resultados brutos
    
    with st.spinner(f"Executando {len(sample_sizes) * len(k_values) * n_repetitions} experimentos..."):
        progress_bar = st.progress(0)
        total_experiments = len(k_values) * len(sample_sizes) * n_repetitions
        current_experiment = 0

        # <<< MUDAN√áA 2: Loop externo para as repeti√ß√µes >>>
        for i in range(n_repetitions):
            # Usamos uma semente diferente para cada repeti√ß√£o para garantir variedade
            current_random_state = initial_random_state + i

            for sample_size in sample_sizes:
                try:
                    # Usar a semente vari√°vel na cria√ß√£o do subconjunto
                    X_subset, y_subset = create_balanced_subset(X, y, sample_size, current_random_state)
                    
                    for k in k_values:
                        current_experiment += 1
                        progress_bar.progress(current_experiment / total_experiments)
                        
                        try:
                            # <<< MUDAN√áA 3: Usar a semente vari√°vel tamb√©m na divis√£o treino-teste >>>
                            X_train, X_test, y_train, y_test = train_test_split(
                                X_subset, y_subset, test_size=0.2, random_state=current_random_state, stratify=y_subset
                            )
                            
                            scaler = StandardScaler()
                            X_train_scaled = scaler.fit_transform(X_train)
                            X_test_scaled = scaler.transform(X_test)
                            
                            knn = KNeighborsClassifier(n_neighbors=k)
                            knn.fit(X_train_scaled, y_train)
                            
                            y_pred = knn.predict(X_test_scaled)
                            
                            # Calcular todas as m√©tricas
                            accuracy = accuracy_score(y_test, y_pred)
                            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
                            precision_macro = report['macro avg']['precision']
                            recall_macro = report['macro avg']['recall']
                            f1_macro = report['macro avg']['f1-score']

                            # Salvar os resultados brutos desta execu√ß√£o
                            all_results.append({
                                'Tamanho_Amostra': sample_size,
                                'K': k,
                                'Acuracia': accuracy,
                                'Precisao': precision_macro,
                                'Revocacao': recall_macro,
                                'F1-Score': f1_macro
                            })
                            
                        except Exception as e:
                            # Silenciosamente ignora erros em execu√ß√µes individuais para n√£o parar o processo
                            pass
                except Exception as e:
                    st.error(f"Erro ao criar subset com {sample_size} amostras na repeti√ß√£o {i+1}: {str(e)}")

    # <<< MUDAN√áA 4: Processar os resultados ap√≥s todas as execu√ß√µes >>>
    if all_results:
        results_df = pd.DataFrame(all_results)
        
        # Agrupar por configura√ß√£o e calcular m√©dia e desvio padr√£o
        grouped = results_df.groupby(['Tamanho_Amostra', 'K'])
        mean_results = grouped.mean()
        std_results = grouped.std().fillna(0) # .fillna(0) para casos sem varia√ß√£o

        # Fun√ß√£o para formatar "m√©dia ¬± desvio padr√£o"
        def format_mean_std(mean_df, std_df, metric):
            formatted_series = (mean_df[metric].round(3).astype(str) + 
                                " ¬± " + 
                                std_df[metric].round(3).astype(str))
            return formatted_series.unstack()

        # Criar as tabelas formatadas
        pivot_accuracy = format_mean_std(mean_results, std_results, 'Acuracia')
        pivot_f1 = format_mean_std(mean_results, std_results, 'F1-Score')

        st.markdown("#### üìä Tabela de Resultados (Acur√°cia: M√©dia ¬± Desvio Padr√£o)")
        st.dataframe(pivot_accuracy, use_container_width=True)

        st.markdown("#### üìä Tabela de Resultados (F1-Score Macro: M√©dia ¬± Desvio Padr√£o)")
        st.dataframe(pivot_f1, use_container_width=True)

        # <<< ADICIONE ESTE BLOCO PARA EXIBIR AS M√âTRICAS FALTANTES >>>
        pivot_precision = format_mean_std(mean_results, std_results, 'Precisao')
        pivot_recall = format_mean_std(mean_results, std_results, 'Revocacao')

        st.markdown("#### üìä Tabela de Resultados (Precis√£o Macro: M√©dia ¬± Desvio Padr√£o)")
        st.dataframe(pivot_precision, use_container_width=True)

        st.markdown("#### üìä Tabela de Resultados (Revoca√ß√£o Macro: M√©dia ¬± Desvio Padr√£o)")
        st.dataframe(pivot_recall, use_container_width=True)
        # --- FIM DO BLOCO ---
        
        # O heatmap deve usar apenas a m√©dia (dados num√©ricos)
        pivot_accuracy_mean = mean_results['Acuracia'].unstack()
        fig_heatmap = px.imshow(
            pivot_accuracy_mean.values,
            x=[f"K={k}" for k in pivot_accuracy_mean.columns],
            y=[f"Amostras={s}" for s in pivot_accuracy_mean.index],
            color_continuous_scale="Viridis",
            title="üî• Mapa de Calor: Acur√°cia M√©dia",
            text_auto=".3f"
        )
        st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # Gr√°ficos de tend√™ncia tamb√©m usam a m√©dia
        st.markdown("#### üìà An√°lise de Tend√™ncias (baseada na m√©dia de 10 execu√ß√µes)")
        col1, col2 = st.columns(2)
        with col1:
            fig_k_trend = px.line(
                mean_results.reset_index().groupby('K')['Acuracia'].mean().reset_index(),
                x='K', y='Acuracia', title="Tend√™ncia da Acur√°cia M√©dia por K", markers=True
            )
            st.plotly_chart(fig_k_trend, use_container_width=True)
        with col2:
            fig_sample_trend = px.line(
                mean_results.reset_index().groupby('Tamanho_Amostra')['Acuracia'].mean().reset_index(),
                x='Tamanho_Amostra', y='Acuracia', title="Tend√™ncia da Acur√°cia M√©dia por Tamanho da Amostra", markers=True
            )
            st.plotly_chart(fig_sample_trend, use_container_width=True)
    else:
        st.error("Nenhum resultado foi gerado. Verifique as configura√ß√µes e os dados de entrada.")

    return None # A fun√ß√£o agora apenas exibe os resultados

    """Executa an√°lise sistem√°tica do exerc√≠cio variando K e tamanho das amostras"""
    st.markdown("### üìã An√°lise Sistem√°tica - Exerc√≠cio")
    
    results_table = []
    confusion_matrices = {}
    
    with st.spinner("Executando an√°lise sistem√°tica..."):
        progress_bar = st.progress(0)
        total_experiments = len(k_values) * len(sample_sizes)
        current_experiment = 0
        
        for sample_size in sample_sizes:
            st.write(f"**Testando com {sample_size} amostras por classe...**")
            
            # Criar subset balanceado com sample_size por classe
            try:
                X_subset, y_subset = create_balanced_subset(X, y, sample_size, random_state)
                
                for k in k_values:
                    current_experiment += 1
                    progress_bar.progress(current_experiment / total_experiments)
                    
                    # Executar KNN
                    try:
                        # Use 80% para treino, 20% para teste do subset
                        X_train, X_test, y_train, y_test = train_test_split(
                            X_subset, y_subset, test_size=0.2, random_state=random_state, stratify=y_subset
                        )
                        
                        # Padroniza√ß√£o
                        scaler = StandardScaler()
                        X_train_scaled = scaler.fit_transform(X_train)
                        X_test_scaled = scaler.transform(X_test)
                        
                        # Treinamento
                        knn = KNeighborsClassifier(n_neighbors=k)
                        knn.fit(X_train_scaled, y_train)
                        
                        # Predi√ß√µes
                        y_pred = knn.predict(X_test_scaled)
                        accuracy = accuracy_score(y_test, y_pred)

                        # --- IN√çCIO DA CORRE√á√ÉO ---
                        # Adicione este bloco para calcular as m√©tricas que faltavam
                        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
                        precision_macro = report['macro avg']['precision']
                        recall_macro = report['macro avg']['recall']
                        f1_macro = report['macro avg']['f1-score']
                        # --- FIM DA CORRE√á√ÉO ---

                        # Salvar resultados
                        results_table.append({
                            'Tamanho_Amostra': sample_size,
                            'K': k,
                            'Acuracia': accuracy,
                            'Precisao': precision_macro,
                            'Revocacao': recall_macro,
                            'F1-Score': f1_macro,
                            'N_Treino': len(X_train),
                            'N_Teste': len(X_test)
                        })
                        
                        # Salvar matriz de confus√£o para casos espec√≠ficos
                        if k == 5:  # Salva matriz para k=5 como exemplo
                            cm = confusion_matrix(y_test, y_pred)
                            confusion_matrices[f"Sample_{sample_size}_K_{k}"] = cm
                            
                    except Exception as e:
                        st.warning(f"Erro para K={k}, Amostra={sample_size}: {str(e)}")
                        
            except Exception as e:
                st.error(f"Erro ao criar subset com {sample_size} amostras: {str(e)}")
    
    # Criar tabela de resultados
    if results_table:
        results_df = pd.DataFrame(results_table)
        
        # Pivot table como solicitado no exerc√≠cio
        pivot_table = results_df.pivot(index='Tamanho_Amostra', columns='K', values='Acuracia')
        
        st.markdown("#### üìä Tabela de Resultados (Acur√°cia)")
        st.dataframe(pivot_table.round(4), use_container_width=True)
        
         # --- ADICIONE ESTE BLOCO PARA VER AS OUTRAS M√âTRICAS ---
        st.markdown("#### üìä Tabela de Resultados (F1-Score Macro)")
        pivot_f1 = results_df.pivot(index='Tamanho_Amostra', columns='K', values='F1-Score')
        st.dataframe(pivot_f1.round(4), use_container_width=True)

        st.markdown("#### üìä Tabela de Resultados (Precis√£o Macro)")
        pivot_precision = results_df.pivot(index='Tamanho_Amostra', columns='K', values='Precisao')
        st.dataframe(pivot_precision.round(4), use_container_width=True)
        # --- FIM DO BLOCO ---

        # Heatmap da tabela
        fig_heatmap = px.imshow(
            pivot_table.values,
            x=[f"K={k}" for k in pivot_table.columns],
            y=[f"Amostras={s}" for s in pivot_table.index],
            color_continuous_scale="Viridis",
            title="üî• Mapa de Calor: Acur√°cia por K e Tamanho da Amostra",
            text_auto=".3f"
        )
        st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # An√°lise de tend√™ncias
        st.markdown("#### üìà An√°lise de Tend√™ncias")
        col1, col2 = st.columns(2)
        
        with col1:
            # Gr√°fico por K
            fig_k_trend = px.line(
                results_df.groupby('K')['Acuracia'].mean().reset_index(),
                x='K', y='Acuracia',
                title="Tend√™ncia da Acur√°cia por K",
                markers=True
            )
            st.plotly_chart(fig_k_trend, use_container_width=True)
        
        with col2:
            # Gr√°fico por tamanho da amostra
            fig_sample_trend = px.line(
                results_df.groupby('Tamanho_Amostra')['Acuracia'].mean().reset_index(),
                x='Tamanho_Amostra', y='Acuracia',
                title="Tend√™ncia da Acur√°cia por Tamanho da Amostra",
                markers=True
            )
            st.plotly_chart(fig_sample_trend, use_container_width=True)
        
        # Mostrar algumas matrizes de confus√£o
        if confusion_matrices:
            st.markdown("#### üîÑ Matrizes de Confus√£o (Exemplos)")
            for name, cm in list(confusion_matrices.items())[:3]:  # Mostrar at√© 3 exemplos
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.write(f"**{name.replace('_', ' ')}**")
                    st.dataframe(pd.DataFrame(cm, 
                                            columns=target_names[:cm.shape[1]], 
                                            index=target_names[:cm.shape[0]]))
                with col2:
                    fig_cm = px.imshow(
                        cm, text_auto=True,
                        title=f"Matriz de Confus√£o - {name.replace('_', ' ')}",
                        color_continuous_scale="Blues"
                    )
                    st.plotly_chart(fig_cm, use_container_width=True)
    
    return results_df if results_table else None


def create_balanced_subset(X, y, samples_per_class, random_state=42):
    """Cria um subset balanceado com n amostras por classe"""
    np.random.seed(random_state)
    
    X_subset = []
    y_subset = []
    
    for class_label in np.unique(y):
        # √çndices da classe atual
        class_indices = np.where(y == class_label)[0]
        
        # Se h√° menos amostras que o solicitado, usa todas
        n_samples = min(samples_per_class, len(class_indices))
        
        # Seleciona aleatoriamente n_samples
        selected_indices = np.random.choice(class_indices, size=n_samples, replace=False)
        
        X_subset.extend(X.iloc[selected_indices].values)
        y_subset.extend(y.iloc[selected_indices].values)
    
    return pd.DataFrame(X_subset, columns=X.columns), pd.Series(y_subset)

def create_prediction_interface(model, scaler, feature_names, target_names):
    """Interface para fazer predi√ß√µes"""
    st.markdown("### üéØ Fazer Predi√ß√µes")
    
    st.write("Insira os valores das features para fazer uma predi√ß√£o:")
    
    input_values = []
    cols = st.columns(2)
    
    for i, feature in enumerate(feature_names):
        with cols[i % 2]:
            value = st.number_input(
                f"{feature}",
                value=0.0,
                step=0.1,
                format="%.2f"
            )
            input_values.append(value)
    
    if st.button("üîÆ Fazer Predi√ß√£o"):
        try:
            # Prepara os dados
            input_array = np.array(input_values).reshape(1, -1)
            input_scaled = scaler.transform(input_array)
            
            # Faz predi√ß√£o
            prediction = model.predict(input_scaled)[0]
            prediction_proba = model.predict_proba(input_scaled)[0]
            
            # Ensure prediction is valid index
            if prediction < len(target_names):
                predicted_class = target_names[prediction]
            else:
                predicted_class = f"Class_{prediction}"
            
            # Exibe resultado
            st.success(f"üéØ Predi√ß√£o: **{predicted_class}**")
            
            # Probabilidades - evita usar % no formato
            prob_df = pd.DataFrame({
                'Classe': target_names[:len(prediction_proba)],
                'Probabilidade': prediction_proba
            }).sort_values('Probabilidade', ascending=False)
            
            # Mostra as probabilidades como texto tamb√©m
            st.write("**Probabilidades:**")
            for idx, row in prob_df.iterrows():
                prob_percent = row['Probabilidade'] * 100
                st.write(f"- {row['Classe']}: {prob_percent:.2f}%")
            
            fig_prob = px.bar(
                prob_df,
                x='Classe',
                y='Probabilidade',
                title="üìä Probabilidades por Classe",
                color='Probabilidade',
                color_continuous_scale='viridis'
            )
            st.plotly_chart(fig_prob, use_container_width=True)
        except Exception as e:
            st.error(f"Erro na predi√ß√£o: {str(e)}")

def run_exercise_analysis_proportions(X, y, target_names, k_values, train_proportions, initial_random_state, compare_scaling=True):
    """Executa an√°lise sistem√°tica variando K, propor√ß√£o treino/teste e normaliza√ß√£o"""
    st.markdown("### üìã An√°lise Sistem√°tica - Por Propor√ß√£o de Treino")
    
    n_repetitions = 10
    st.info(f"Executando cada configura√ß√£o {n_repetitions} vezes para calcular m√©dia e desvio padr√£o.")

    all_results = []
    scaling_options = ['Com normaliza√ß√£o', 'Sem normaliza√ß√£o'] if compare_scaling else ['Com normaliza√ß√£o']
    
    with st.spinner(f"Executando {len(train_proportions) * len(k_values) * len(scaling_options) * n_repetitions} experimentos..."):
        progress_bar = st.progress(0)
        total_experiments = len(k_values) * len(train_proportions) * len(scaling_options) * n_repetitions
        current_experiment = 0

        for i in range(n_repetitions):
            current_random_state = initial_random_state + i
            
            for train_prop in train_proportions:
                for use_scaling in scaling_options:
                    for k in k_values:
                        current_experiment += 1
                        progress_bar.progress(current_experiment / total_experiments)
                        
                        try:
                            # Divis√£o treino-teste
                            X_train, X_test, y_train, y_test = train_test_split(
                                X, y, train_size=train_prop, random_state=current_random_state, stratify=y
                            )
                            
                            # Normaliza√ß√£o condicional
                            if use_scaling == 'Com normaliza√ß√£o':
                                scaler = StandardScaler()
                                X_train_scaled = scaler.fit_transform(X_train)
                                X_test_scaled = scaler.transform(X_test)
                            else:
                                X_train_scaled = X_train.values
                                X_test_scaled = X_test.values
                            
                            # Treinamento e predi√ß√£o
                            knn = KNeighborsClassifier(n_neighbors=k)
                            knn.fit(X_train_scaled, y_train)
                            y_pred = knn.predict(X_test_scaled)
                            
                            # M√©tricas
                            accuracy = accuracy_score(y_test, y_pred)
                            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
                            precision_macro = report['macro avg']['precision']
                            recall_macro = report['macro avg']['recall']
                            f1_macro = report['macro avg']['f1-score']

                            all_results.append({
                                'Proporcao_Treino': f"{int(train_prop*100)}%",
                                'K': k,
                                'Normalizacao': use_scaling,
                                'Acuracia': accuracy,
                                'Precisao': precision_macro,
                                'Revocacao': recall_macro,
                                'F1-Score': f1_macro
                            })
                            
                        except Exception as e:
                            continue

    if all_results:
        results_df = pd.DataFrame(all_results)
        
        # Agrupar e calcular estat√≠sticas
        grouped = results_df.groupby(['Proporcao_Treino', 'K', 'Normalizacao'])
        mean_results = grouped.mean()
        std_results = grouped.std().fillna(0)

        def format_mean_std(mean_df, std_df, metric):
            formatted_series = (mean_df[metric].round(3).astype(str) + " ¬± " + std_df[metric].round(3).astype(str))
            return formatted_series

        # Tabelas por normaliza√ß√£o
        for scaling_type in scaling_options:
            st.markdown(f"#### üìä Resultados - {scaling_type}")
            
            subset_mean = mean_results.xs(scaling_type, level='Normalizacao')
            subset_std = std_results.xs(scaling_type, level='Normalizacao')
            
            for metric in ['Acuracia', 'F1-Score', 'Precisao', 'Revocacao']:
                pivot_table = format_mean_std(subset_mean, subset_std, metric).unstack()
                st.markdown(f"**{metric} (M√©dia ¬± Desvio Padr√£o)**")
                st.dataframe(pivot_table, use_container_width=True)
        
        # Compara√ß√£o com/sem normaliza√ß√£o se aplic√°vel
        if compare_scaling:
            st.markdown("#### üìà Compara√ß√£o: Com vs Sem Normaliza√ß√£o")
            
            comparison_data = []
            for _, row in results_df.groupby(['Proporcao_Treino', 'K', 'Normalizacao'])['Acuracia'].mean().reset_index().iterrows():
                comparison_data.append({
                    'Configura√ß√£o': f"{row['Proporcao_Treino']} - K={row['K']}",
                    'Normaliza√ß√£o': row['Normalizacao'],
                    'Acur√°cia M√©dia': row['Acuracia']
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            
            fig_comparison = px.bar(
                comparison_df,
                x='Configura√ß√£o',
                y='Acur√°cia M√©dia',
                color='Normaliza√ß√£o',
                title="üîÑ Impacto da Normaliza√ß√£o na Acur√°cia",
                barmode='group'
            )
            fig_comparison.update_xaxes(tickangle=45)
            st.plotly_chart(fig_comparison, use_container_width=True)
        
        # An√°lise cr√≠tica autom√°tica
        st.markdown("#### üß† An√°lise Cr√≠tica Autom√°tica")
        
        best_k = mean_results['Acuracia'].idxmax()[1]  # K da melhor configura√ß√£o
        worst_k = mean_results['Acuracia'].idxmin()[1]  # K da pior configura√ß√£o
        
        st.markdown(f"""
        **Observa√ß√µes sobre vi√©s vs. vari√¢ncia:**
        - **K={best_k}** mostrou melhor desempenho m√©dio, sugerindo bom equil√≠brio entre vi√©s e vari√¢ncia
        - **K={worst_k}** teve pior desempenho, indicando poss√≠vel overfitting (K muito baixo) ou underfitting (K muito alto)
        
        **Efeito da normaliza√ß√£o:**
        {f"- A normaliza√ß√£o mostrou impacto significativo nos resultados, confirmando a import√¢ncia da padroniza√ß√£o para k-NN" if compare_scaling else "- Executado apenas com normaliza√ß√£o (recomendado para k-NN)"}
        
        **Efeito do tamanho do conjunto de treino:**
        - Propor√ß√µes maiores de treino tendem a melhorar a acur√°cia, mas reduzem a confiabilidade da avalia√ß√£o
        - O desvio padr√£o indica a estabilidade do modelo across diferentes divis√µes aleat√≥rias
        """)
        
        # Download dos resultados
        export_df = mean_results.join(std_results, lsuffix='_mean', rsuffix='_std')
        st.download_button(
           label="üì• Baixar Resultados Completos (CSV)",
           data=export_df.to_csv().encode('utf-8'),
           file_name='resultados_proporcoes.csv',
           mime='text/csv',
        )

    else:
        st.error("Nenhum resultado foi gerado. Verifique as configura√ß√µes.")

def main():
    # Header
    st.markdown("<h1 class='main-header'>ü§ñ k-NN Interactive Analyzer</h1>", unsafe_allow_html=True)
    st.markdown("**An√°lise interativa de classifica√ß√£o com k-Nearest Neighbors**")
    
    # Sidebar para configura√ß√µes
    st.sidebar.header("‚öôÔ∏è Configura√ß√µes")
    
    # Sele√ß√£o do dataset
    dataset_choice = st.sidebar.selectbox(
        "üìä Escolha o Dataset:",
        ["Iris", "Wine"]
    )
    
    # Carrega dados
    try:
        X, y, target_names, description = load_dataset(dataset_choice)
    except Exception as e:
        st.error(f"Erro ao carregar dataset: {str(e)}")
        return
    
    # Configura√ß√µes do modelo
    st.sidebar.subheader("üîß Par√¢metros do Modelo")
    
    k_value = st.sidebar.slider(
        "Valor de k:",
        min_value=1,
        max_value=min(20, len(X) // 3),
        value=5,
        help="N√∫mero de vizinhos mais pr√≥ximos a considerar"
    )
    
    test_size = st.sidebar.slider(
        "Tamanho do conjunto de teste:",
        min_value=0.1,
        max_value=0.5,
        value=0.2,
        step=0.05,
        format="%.2f",
        help="Porcentagem dos dados para teste"
    )
    
    random_state = st.sidebar.number_input(
        "Random State:",
        value=42,
        help="Semente para reprodutibilidade"
    )
    
    # Configura√ß√µes do exerc√≠cio espec√≠fico
    st.sidebar.subheader("üìã Configura√ß√µes do Exerc√≠cio")
    
    use_exercise_mode = st.sidebar.checkbox(
        "Modo Exerc√≠cio (Tabela K vs Tamanho da Amostra)",
        help="Executa an√°lise sistem√°tica variando K e tamanho das amostras"
    )
    
    if use_exercise_mode:
        exercise_type = st.sidebar.radio(
            "Tipo de an√°lise:",
            ["Por propor√ß√£o de treino", "Por amostras por classe"],
            help="Escolha o tipo de varia√ß√£o conforme o exerc√≠cio"
        )
        
        if exercise_type == "Por propor√ß√£o de treino":
            train_proportions = st.sidebar.multiselect(
                "Propor√ß√µes de treino:",
                options=[0.6, 0.7, 0.8],
                default=[0.6, 0.7, 0.8],
                help="Propor√ß√£o dos dados para treinamento (60%, 70%, 80%)"
            )
        else:
            sample_sizes = st.sidebar.multiselect(
                "Tamanhos de amostra por classe:",
                options=[5, 10, 15, 20, 25, 30],
                default=[5, 10, 15, 20],
                help="N√∫mero de amostras por classe para treino"
            )
        
        k_values = st.sidebar.multiselect(
            "Valores de K para testar:",
            options=[1, 3, 5, 7, 9],
            default=[1, 3, 5, 7, 9],
            help="Valores de K a serem testados"
        )
        
        compare_scaling = st.sidebar.checkbox(
            "Comparar com/sem normaliza√ß√£o",
            value=True,
            help="Executa an√°lise com e sem StandardScaler"
        )
    
    # Op√ß√µes de visualiza√ß√£o
    st.sidebar.subheader("üìä Op√ß√µes de Visualiza√ß√£o")
    show_data_overview = st.sidebar.checkbox("Vis√£o Geral dos Dados", True)
    show_feature_analysis = st.sidebar.checkbox("An√°lise de Features", True)
    show_pca = st.sidebar.checkbox("Visualiza√ß√£o PCA", True)
    show_optimization = st.sidebar.checkbox("Otimiza√ß√£o de k", False)
    show_prediction = st.sidebar.checkbox("Interface de Predi√ß√£o", False)
    
    # Conte√∫do principal
    if show_data_overview:
        create_data_overview(X, y, target_names, description)
        st.divider()
    
    if show_feature_analysis:
        create_feature_analysis(X, y, target_names)
        st.divider()
    
    if show_pca:
        pca, X_pca = create_pca_visualization(X, y, target_names)
        st.divider()
    
    # An√°lise do modelo atual
    if not use_exercise_mode:
        st.markdown("### üöÄ An√°lise do Modelo k-NN")
        
        with st.spinner("Treinando modelo..."):
            try:
                results = run_knn_analysis(X, y, target_names, k_value, test_size, random_state)
                create_results_visualization(results, target_names, k_value)
            except Exception as e:
                st.error(f"Erro durante an√°lise do modelo: {str(e)}")
    else:
        # Modo exerc√≠cio
        if k_values:
            if exercise_type == "Por propor√ß√£o de treino":
                if train_proportions:
                    run_exercise_analysis_proportions(X, y, target_names, k_values, train_proportions, random_state, compare_scaling)
                else:
                    st.warning("‚ö†Ô∏è Selecione pelo menos uma propor√ß√£o de treino e um valor de K")
            else:
                if sample_sizes:
                    run_exercise_analysis(X, y, target_names, k_values, sample_sizes, random_state)
                else:
                    st.warning("‚ö†Ô∏è Selecione pelo menos um tamanho de amostra e um valor de K")
        else:
            st.warning("‚ö†Ô∏è Selecione pelo menos um valor de K para o exerc√≠cio")
    
    if show_optimization and not use_exercise_mode:
        st.divider()
        try:
            optimal_k = k_optimization_analysis(X, y, target_names, test_size, random_state)
        except Exception as e:
            st.error(f"Erro na otimiza√ß√£o: {str(e)}")
    
    if show_prediction and not use_exercise_mode:
        st.divider()
        try:
            if 'results' in locals():
                create_prediction_interface(results['model'], results['scaler'], X.columns, target_names)
            else:
                st.info("Execute a an√°lise do modelo primeiro para usar a interface de predi√ß√£o")
        except Exception as e:
            st.error(f"Erro na interface de predi√ß√£o: {str(e)}")
    
    # Informa√ß√µes sobre o exerc√≠cio
    with st.expander("üìã Sobre o Exerc√≠cio (Prof. Jos√© Alfredo Costa)"):
        st.markdown("""
        **Objetivo do Exerc√≠cio:**
        
        Testar o algoritmo KNN nas bases Iris e Wine variando:
        - **K**: 1, 3, 5, 7, 9 (n√∫mero de vizinhos mais pr√≥ximos)
        - **Propor√ß√£o de treino**: 60%, 70%, 80% (conforme exerc√≠cio original)
        - **Normaliza√ß√£o**: Comparar com e sem StandardScaler
        
        **Como usar o Modo Exerc√≠cio:**
        1. ‚úÖ Marque "Modo Exerc√≠cio" na barra lateral
        2. üìä Escolha "Por propor√ß√£o de treino" (conforme exerc√≠cio) ou "Por amostras por classe"
        3. üî¢ Selecione os valores de K e propor√ß√µes para testar
        4. ‚öñÔ∏è Marque "Comparar com/sem normaliza√ß√£o" para an√°lise completa
        5. üöÄ O sistema executar√° automaticamente todas as combina√ß√µes
        6. üìà Visualize resultados, an√°lise cr√≠tica e baixe os dados
        
        **M√©tricas reportadas (conforme solicitado):**
        - Acur√°cia, precis√£o, revoca√ß√£o, F1-score (macro)
        - Matriz de confus√£o
        - Tabelas sintetizando resultados por k e propor√ß√£o de treino
        - An√°lise cr√≠tica sobre vi√©s vs. vari√¢ncia e efeito da escala
        
        **Reprodutibilidade garantida:**
        - 10 repeti√ß√µes com seeds diferentes
        - M√©dia ¬± desvio padr√£o para maior estabilidade
        """)
    
    # Informa√ß√µes adicionais
    with st.expander("‚ÑπÔ∏è Sobre o k-NN"):
        st.markdown("""
        **k-Nearest Neighbors (k-NN)** √© um algoritmo de aprendizado supervisionado usado para classifica√ß√£o e regress√£o.
        
        **Como funciona:**
        - Para classificar um novo ponto, encontra os k pontos mais pr√≥ximos no conjunto de treinamento
        - A classifica√ß√£o √© feita por voto majorit√°rio dos k vizinhos
        - A dist√¢ncia √© geralmente calculada usando a dist√¢ncia euclidiana
        
        **Vantagens:**
        - ‚úÖ Simples de entender e implementar
        - ‚úÖ N√£o faz suposi√ß√µes sobre a distribui√ß√£o dos dados
        - ‚úÖ Funciona bem com datasets pequenos
        
        **Desvantagens:**
        - ‚ùå Computacionalmente caro para datasets grandes
        - ‚ùå Sens√≠vel √† escala das features (por isso a padroniza√ß√£o √© importante)
        - ‚ùå Performance degrada em altas dimens√µes (curse of dimensionality)
        """)

if __name__ == "__main__":
    main()