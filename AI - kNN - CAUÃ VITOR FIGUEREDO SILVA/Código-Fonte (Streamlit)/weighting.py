import streamlit as st
import pandas as pd
from sklearn.datasets import load_iris, load_wine
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import plotly.express as px

# --- FUN√á√ÉO PARA CARREGAR DADOS ---
@st.cache_data
def load_data(dataset_name):
    if dataset_name == 'Iris':
        data = load_iris()
        description = "Dataset Iris: 150 amostras, 4 features. Classes bem separadas."
    elif dataset_name == 'Wine':
        data = load_wine()
        description = "Dataset Wine: 178 amostras, 13 features. Mais complexo que o Iris."
    
    X = pd.DataFrame(data.data, columns=data.feature_names)
    y = pd.Series(data.target)
    return X, y, description

# --- FUN√á√ÉO PRINCIPAL DA AN√ÅLISE ---
def run_comparison_analysis(X, y, k_values, train_size, compare_scaling, weights_options, random_state):
    """
    Executa a an√°lise comparativa de 'weights' no k-NN,
    considerando tamb√©m o impacto da normaliza√ß√£o, com M√öLTIPLAS REPETI√á√ïES.
    """
    n_repetitions = 10 # Executar 10 vezes
    st.info(f"Executando cada configura√ß√£o {n_repetitions} vezes para K = {k_values} com {int(train_size*100)}% de dados para treino. Isso pode levar um momento.")

    all_results = []
    scaling_options = ['Com Normaliza√ß√£o', 'Sem Normaliza√ß√£o'] if compare_scaling else ['Com Normaliza√ß√£o']
    
    progress_bar = st.progress(0)
    total_iterations = n_repetitions * len(scaling_options) * len(weights_options) * len(k_values)
    current_iteration = 0

    # Loop de 10 repeti√ß√µes
    for i in range(n_repetitions):
        current_random_state = random_state + i # Usa uma seed diferente a cada vez

        # Loop para todas as combina√ß√µes de par√¢metros
        for scale_opt in scaling_options:
            for weight_opt in weights_options:
                for k in k_values:
                    current_iteration += 1
                    progress_bar.progress(current_iteration / total_iterations)

                    # Divis√£o dos dados
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, train_size=train_size, random_state=current_random_state, stratify=y
                    )

                    # Normaliza√ß√£o condicional
                    if scale_opt == 'Com Normaliza√ß√£o':
                        scaler = StandardScaler()
                        X_train_processed = scaler.fit_transform(X_train)
                        X_test_processed = scaler.transform(X_test)
                    else: # Sem Normaliza√ß√£o
                        X_train_processed = X_train.values
                        X_test_processed = X_test.values

                    # Treinamento e Predi√ß√£o
                    try:
                        knn = KNeighborsClassifier(n_neighbors=k, weights=weight_opt)
                        knn.fit(X_train_processed, y_train)
                        y_pred = knn.predict(X_test_processed)
                        accuracy = accuracy_score(y_test, y_pred)
                        
                        # Armazena o resultado bruto
                        all_results.append({
                            'K': k,
                            'Pondera√ß√£o (Weights)': weight_opt,
                            'Normaliza√ß√£o': scale_opt,
                            'Acur√°cia': accuracy
                        })
                    except Exception as e:
                        st.warning(f"N√£o foi poss√≠vel executar para K={k} na repeti√ß√£o {i+1}: {e}")

    if not all_results:
        st.error("Nenhum resultado foi gerado. Verifique os par√¢metros.")
        return

    # Processar os resultados para calcular m√©dia e desvio padr√£o
    results_df = pd.DataFrame(all_results)
    grouped = results_df.groupby(['K', 'Pondera√ß√£o (Weights)', 'Normaliza√ß√£o'])['Acur√°cia']
    stats_df = grouped.agg(['mean', 'std']).reset_index().fillna(0)
    stats_df.rename(columns={'mean': 'Acur√°cia M√©dia', 'std': 'Desvio Padr√£o'}, inplace=True)

    # Exibir os resultados
    st.subheader("üìä Tabela de Resultados (M√©dia e Desvio Padr√£o de 10 Execu√ß√µes)")
    st.dataframe(stats_df.round(4), use_container_width=True)

    st.subheader("üìà Gr√°fico Comparativo de Desempenho (com Desvio Padr√£o)")
    
    fig = px.bar(
        stats_df,
        x='K',
        y='Acur√°cia M√©dia',
        error_y='Desvio Padr√£o', # Adiciona barras de erro
        color='Pondera√ß√£o (Weights)',
        barmode='group',
        facet_row='Normaliza√ß√£o',
        title="Impacto da Pondera√ß√£o ('uniform' vs 'distance') na Acur√°cia do k-NN",
        labels={'Acur√°cia M√©dia': 'Acur√°cia M√©dia do Modelo'},
        height=700
    )
    # Ajuste no eixo Y para acomodar a acur√°cia mais baixa do Wine sem normaliza√ß√£o
    fig.update_yaxes(range=[0.4, 1.01]) 
    st.plotly_chart(fig, use_container_width=True)


# --- INTERFACE DO STREAMLIT ---
st.set_page_config(layout="wide")

st.title("üéØ Comparador de Pondera√ß√£o no k-NN (Iris e Wine)")
st.markdown("Este aplicativo compara o desempenho do k-NN usando `weights='uniform'` vs. `weights='distance'`, mostrando tamb√©m o impacto da normaliza√ß√£o em diferentes datasets.")

# --- BARRA LATERAL COM OS CONTROLES ---
st.sidebar.header("‚öôÔ∏è Par√¢metros do Experimento")

dataset_choice = st.sidebar.selectbox(
    'Escolha o Dataset',
    ['Iris', 'Wine']
)

k_values = st.sidebar.multiselect(
    'Valores de K para Testar',
    options=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15],
    default=[1, 3, 5, 7, 9],
    help="Valores de K √≠mpares s√£o recomendados para evitar empates."
)

train_size = st.sidebar.slider(
    'Propor√ß√£o de Dados para Treino',
    min_value=0.1, max_value=0.9, value=0.7, step=0.1
)

compare_scaling = st.sidebar.checkbox(
    'Analisar com e sem normaliza√ß√£o',
    value=True,
    help="Se marcado, executa os testes duas vezes: uma com StandardScaler e outra sem."
)

weights_options = ['uniform', 'distance']
random_state = st.sidebar.number_input('Semente Aleat√≥ria (Random State)', value=42)

# --- EXECU√á√ÉO ---
# Carrega os dados com base na escolha da barra lateral
X, y, description = load_data(dataset_choice)
st.write(f"**Dataset Selecionado:** {dataset_choice}. {description}")

if st.button("üöÄ Executar An√°lise Robusta (10 Repeti√ß√µes)"):
    if not k_values:
        st.warning("Por favor, selecione pelo menos um valor de K.")
    else:
        run_comparison_analysis(
            X=X,
            y=y,
            k_values=k_values,
            train_size=train_size,
            compare_scaling=compare_scaling,
            weights_options=weights_options,
            random_state=random_state
        )

